{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a2492d-eef1-461a-b714-9b75dc79ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d125ee8d-e207-47a0-a20d-fc2ab028b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dharmraj/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0d038b-5662-40f4-b6a7-d458bb451b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>morning</td>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>noon</td>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>noon</td>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day Time of Tweet  \\\n",
       "0  2018      8   18       morning   \n",
       "1  2018      8   18          noon   \n",
       "2  2017      8   18         night   \n",
       "3  2022      6    8       morning   \n",
       "4  2022      6    8          noon   \n",
       "\n",
       "                                                text sentiment     Platform  \n",
       "0              What a great day!!! Looks like dream.  positive    Twitter    \n",
       "1     I feel sorry, I miss you here in the sea beach  positive    Facebook   \n",
       "2                                     Don't angry me  negative     Facebook  \n",
       "3  We attend in the class just for listening teac...  negative    Facebook   \n",
       "4                  Those who want to go, let them go  negative   Instagram   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentiment_analysis.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd72d61-123f-4e60-8389-a33e04ecc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Day\", 'Year', 'Month', 'Time of Tweet', 'Platform'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa1ad44-febf-469c-a90a-de649f5a2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0              What a great day!!! Looks like dream.  positive\n",
       "1     I feel sorry, I miss you here in the sea beach  positive\n",
       "2                                     Don't angry me  negative\n",
       "3  We attend in the class just for listening teac...  negative\n",
       "4                  Those who want to go, let them go  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c45074-432d-47e7-bc79-fffbae6943b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018e1ded-b850-4214-aa7a-f13134185813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d88288-e935-4014-94af-71702cf5952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "df[\"label_sentiment\"] = lb.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196e3348-62ad-4bbe-b802-3ed0a27b956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "0              What a great day!!! Looks like dream.  positive   \n",
       "1     I feel sorry, I miss you here in the sea beach  positive   \n",
       "2                                     Don't angry me  negative   \n",
       "3  We attend in the class just for listening teac...  negative   \n",
       "4                  Those who want to go, let them go  negative   \n",
       "\n",
       "   label_sentiment  \n",
       "0                2  \n",
       "1                2  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6b883b-eef2-4fa9-bae7-b1ce49c827ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text               0\n",
       "sentiment          0\n",
       "label_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d75285b-a9d6-4bba-a8cf-7f220fde1ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     199\n",
       "positive    166\n",
       "negative    134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5ad03c-f3e7-456a-bb66-ae7a9799929e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9d0524-7123-488b-a1bf-f71eee202f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_counts = df[\"sentiment\"].value_counts()\n",
    "ax = value_counts.plot(kind='bar')\n",
    "\n",
    "ax.set_xticklabels(['positive', 'negative', 'neutral'], rotation=0)\n",
    "\n",
    "plt.title('Distribution of Emotions')\n",
    "plt.xlabel('Emotions')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb5bd8e-08e9-4033-91c9-48bad73d4664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>According to , a quarter of families under six...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>the plan to not spend money is not going well</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>uploading all my bamboozle pictures of facebook</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>congratulations ! you guys finish a month ear...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>actually, I wish I was back in Tahoe.  I miss...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text sentiment  \\\n",
       "0                What a great day!!! Looks like dream.  positive   \n",
       "1       I feel sorry, I miss you here in the sea beach  positive   \n",
       "2                                       Don't angry me  negative   \n",
       "3    We attend in the class just for listening teac...  negative   \n",
       "4                    Those who want to go, let them go  negative   \n",
       "..                                                 ...       ...   \n",
       "494  According to , a quarter of families under six...  negative   \n",
       "495      the plan to not spend money is not going well  negative   \n",
       "496    uploading all my bamboozle pictures of facebook   neutral   \n",
       "497   congratulations ! you guys finish a month ear...  positive   \n",
       "498   actually, I wish I was back in Tahoe.  I miss...  negative   \n",
       "\n",
       "     label_sentiment  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "..               ...  \n",
       "494                0  \n",
       "495                0  \n",
       "496                1  \n",
       "497                2  \n",
       "498                0  \n",
       "\n",
       "[499 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f297b379-1685-4ea0-ac08-983198b229f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label_sentiment'], train_size=0.80, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da551135-5366-4fa7-8d83-242011a1a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab4bfbce-637a-4acc-9428-688ef2a29e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(list(x_train), padding = True, truncation=True)\n",
    "test_tokens = tokenizer(list(x_test), padding = True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ad8ee6-b7f0-4e05-9257-fc3a784f2910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09358b22-b946-4ef7-9888-b86f7f556c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2065, 2069, 2057, 2071, 2412, 2941, 2022, 3039, 2000, 2994, 2182, 1998, 2079, 2008, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[CLS] if only we could ever actually be allowed to stay here and do that [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens['input_ids'][0])\n",
    "print(tokenizer.decode(train_tokens['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28db0a92-bce6-42f5-b73d-b2744770e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenData(Dataset):\n",
    "    def __init__(self, train = False):\n",
    "        if train:\n",
    "            self.text_data = x_train\n",
    "            self.tokens = train_tokens\n",
    "            self.labels = list(y_train)\n",
    "        else:\n",
    "            self.text_data = x_test\n",
    "            self.tokens = test_tokens\n",
    "            self.labels = list(y_test)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for k, v in self.tokens.items():\n",
    "            sample[k] = torch.tensor(v[idx])\n",
    "        sample['labels'] = torch.tensor(self.labels[idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a557a8f-e0e5-4a4f-9440-78c4d5b60e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataset = TokenData(train = True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TokenData(train = False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d207b01-81b5-45a2-8988-f3a63ab6c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 9\n",
    "bert_model = BertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_classes) \n",
    "optimizer = AdamW(bert_model.parameters(), lr=1e-5) \n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1841cc2-fd0c-4795-8566-90a93d2f8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27c0a63c-fb07-4bb4-a0e9-508a9ad3f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dharmraj/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8778882c-42a4-484b-a3af-c05fc8fb5c87",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbert_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Transfer model to GPU if available\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/transformers/modeling_utils.py:2796\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2795\u001b[0m         )\n\u001b[0;32m-> 2796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/pipx/venvs/jupyterlab/lib/python3.12/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "device = \"cuda\"\n",
    "bert_model.to(device) # Transfer model to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839b315-3b1b-4538-956f-f1d180a99900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "accumulation_steps = 4\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: \", (epoch + 1))\n",
    "    bert_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Check for out-of-bound labels\n",
    "        if (batch['labels'] >= num_classes).any():\n",
    "            print(f\"Out-of-bound label found in batch {i+1}: \", batch['labels'])\n",
    "            continue  # Skip this batch\n",
    "\n",
    "        with autocast():\n",
    "            outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "            pred = outputs.logits\n",
    "\n",
    "            # Debugging prints\n",
    "            #print(f\"Batch {i+1}: input_ids.shape = {batch['input_ids'].shape}, pred.shape = {pred.shape}, labels.shape = {batch['labels'].shape}\")\n",
    "\n",
    "            loss = loss_fn(pred, batch['labels'])\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        train_batch_loss = loss.item()\n",
    "        train_last_loss = train_batch_loss / batch['input_ids'].size(0)\n",
    "        print(f'Training batch {i + 1} last loss: {train_last_loss}')\n",
    "\n",
    "    print(f\"\\nTraining epoch {epoch + 1} loss: \", train_last_loss)\n",
    "\n",
    "    bert_model.eval()\n",
    "    correct = 0\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, batch['labels'])\n",
    "            test_batch_loss = loss.item()\n",
    "            test_last_loss = test_batch_loss / batch['input_ids'].size(0)\n",
    "            #print(f'Testing batch {i + 1} loss: {test_last_loss}')\n",
    "\n",
    "            correct += (logits.argmax(1) == batch['labels']).sum().item()\n",
    "            print(f\"Testing accuracy: {correct / ((i + 1) * batch['input_ids'].size(0))}\")\n",
    "\n",
    "    print(f\"\\nTesting epoch {epoch + 1} last loss: \", test_last_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb53c88-f204-42af-8527-49dded009fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876001b-1cc2-4903-a73e-276af4cdbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_senti = torch.save(bert_model, \"BERTsentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964bfbd-0b7d-414f-a383-71e2156814ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9269b57-8d83-461f-b735-52d08940214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline(\"text-classification\", model_senti, device=device)\n",
    "answer = clf(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbb91b-d341-4827-86d0-d032c1d5b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8e984-df4e-48c8-9b9e-a58024f10d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf(\"Oh my God!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35892aa0-8ace-4bf0-851f-f2b93a6b2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf(\"I am sorry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b35e8c-93f5-488b-846c-627b1f3fa172",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf(\"He put the car in neutral\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a77dc-1e05-42b4-87a0-2bdd52d5c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf(\"There is a book on the desk\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411490b-3a66-490f-9bb0-adc2ff4b5856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
